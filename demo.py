"""
ë”¥í˜ì´í¬ íƒì§€ ì‹œìŠ¤í…œ ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ì–‘í•œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤:
1. ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„
2. ë°°ì¹˜ ì´ë¯¸ì§€ ì²˜ë¦¬  
3. ë¹„ë””ì˜¤ ë¶„ì„
4. ì‹¤ì‹œê°„ ì›¹ìº  ì²˜ë¦¬
5. ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
"""

import cv2
import os
import glob
import json
import argparse
from pathlib import Path
import time
from deepfake_detector import DeepfakeDetectionPipeline

class DeepfakeDemo:
    def __init__(self,
                 yolo_model_path=None,
                 classifier_weights_path=None,
                 confidence_threshold=0.5):
        """
        ë°ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”

        Args:
            yolo_model_path: ì»¤ìŠ¤í…€ YOLO ëª¨ë¸ ê²½ë¡œ
            classifier_weights_path: í›ˆë ¨ëœ ë¶„ë¥˜ê¸° ê²½ë¡œ
            confidence_threshold: íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
        """
        print("ë”¥í˜ì´í¬ íƒì§€ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")

        try:
            self.detector = DeepfakeDetectionPipeline(
                yolo_model_path=yolo_model_path,
                efficientnet_model='efficientnet-b0',
                classifier_weights_path=classifier_weights_path,
                confidence_threshold=confidence_threshold
            )
            print("âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ!")
        except FileNotFoundError as e:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            raise
        except RuntimeError as e:
            print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def analyze_single_image(self, image_path, save_result=True):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„"""
        print(f"\nğŸ“· ì´ë¯¸ì§€ ë¶„ì„: {image_path}")
        
        if not os.path.exists(image_path):
            print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return None
        
        start_time = time.time()
        results = self.detector.detect_deepfake_from_image(image_path)
        process_time = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
        print(f"ğŸ‘¥ íƒì§€ëœ ì–¼êµ´ ìˆ˜: {results['faces_detected']}")
        print(f"ğŸ¯ ì „ì²´ ê²°ê³¼: {results['overall_result']}")
        print(f"ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {results['confidence']:.3f}")
        
        if results['faces_detected'] > 0:
            print("\nì–¼êµ´ë³„ ìƒì„¸ ê²°ê³¼:")
            for face in results['faces']:
                status_emoji = "ğŸš¨" if face['prediction'] == 'fake' else "âœ…"
                print(f"  {status_emoji} ì–¼êµ´ {face['face_id']}: {face['prediction']} "
                      f"(ì‹ ë¢°ë„: {face['confidence']:.3f})")
        
        # ê²°ê³¼ ì‹œê°í™” ì €ì¥
        if save_result and results['faces_detected'] > 0:
            image = cv2.imread(image_path)
            vis_image = self.detector.visualize_results(image, results)
            
            output_path = f"result_{Path(image_path).stem}.jpg"
            cv2.imwrite(output_path, vis_image)
            print(f"ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: {output_path}")
        
        return results
    
    def analyze_batch_images(self, image_dir, output_dir="batch_results"):
        """ë°°ì¹˜ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        print(f"\nğŸ“ ë°°ì¹˜ ì´ë¯¸ì§€ ë¶„ì„: {image_dir}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
        image_files = []
        
        for ext in image_extensions:
            image_files.extend(glob.glob(os.path.join(image_dir, ext)))
            image_files.extend(glob.glob(os.path.join(image_dir, ext.upper())))
        
        if not image_files:
            print(f"âŒ {image_dir}ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“Š ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼
        batch_results = []
        fake_count = 0
        real_count = 0
        
        for i, img_path in enumerate(image_files, 1):
            print(f"\nì§„í–‰ë¥ : {i}/{len(image_files)} - {os.path.basename(img_path)}")
            
            start_time = time.time()
            results = self.detector.detect_deepfake_from_image(img_path)
            process_time = time.time() - start_time
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if results['overall_result'] == 'fake':
                fake_count += 1
                status_emoji = "ğŸš¨"
            elif results['overall_result'] == 'real':
                real_count += 1
                status_emoji = "âœ…"
            else:
                status_emoji = "â“"
            
            print(f"  {status_emoji} {results['overall_result']} "
                  f"(ì‹ ë¢°ë„: {results['confidence']:.3f}, {process_time:.2f}ì´ˆ)")
            
            # ê²°ê³¼ ì €ì¥
            result_data = {
                'filename': os.path.basename(img_path),
                'filepath': img_path,
                'result': results['overall_result'],
                'confidence': results['confidence'],
                'faces_detected': results['faces_detected'],
                'process_time': process_time,
                'faces': results['faces']
            }
            batch_results.append(result_data)
            
            # ì‹œê°í™” ì €ì¥
            if results['faces_detected'] > 0:
                image = cv2.imread(img_path)
                vis_image = self.detector.visualize_results(image, results)
                
                output_filename = f"result_{os.path.splitext(os.path.basename(img_path))[0]}.jpg"
                output_path = os.path.join(output_dir, output_filename)
                cv2.imwrite(output_path, vis_image)
        
        # ë°°ì¹˜ ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“ˆ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"  ì´ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        print(f"  ğŸš¨ ë”¥í˜ì´í¬: {fake_count}ê°œ ({fake_count/len(image_files)*100:.1f}%)")
        print(f"  âœ… ì§„ì§œ: {real_count}ê°œ ({real_count/len(image_files)*100:.1f}%)")
        print(f"  â“ ì–¼êµ´ ì—†ìŒ: {len(image_files)-fake_count-real_count}ê°œ")
        
        # JSON ê²°ê³¼ ì €ì¥
        json_path = os.path.join(output_dir, 'batch_results.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(batch_results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {json_path}")
        
        return batch_results
    
    def analyze_video(self, video_path, frame_interval=30, max_frames=100, save_result=True):
        """ë¹„ë””ì˜¤ ë¶„ì„"""
        print(f"\nğŸ¬ ë¹„ë””ì˜¤ ë¶„ì„: {video_path}")
        
        if not os.path.exists(video_path):
            print(f"âŒ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return None
        
        start_time = time.time()
        results = self.detector.detect_deepfake_from_video(
            video_path,
            frame_interval=frame_interval,
            max_frames=max_frames
        )
        process_time = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
        print(f"ğŸ“Š ë¶„ì„ëœ í”„ë ˆì„: {results['total_frames_analyzed']}ê°œ")
        print(f"ğŸ‘¥ ì–¼êµ´ íƒì§€ëœ í”„ë ˆì„: {results['frames_with_faces']}ê°œ")
        print(f"ğŸš¨ ë”¥í˜ì´í¬ í”„ë ˆì„: {results['fake_frames']}ê°œ")
        print(f"âœ… ì§„ì§œ í”„ë ˆì„: {results['real_frames']}ê°œ")
        print(f"ğŸ¯ ì „ì²´ ê²°ê³¼: {results['overall_result']}")
        print(f"ğŸ“ˆ í‰ê·  ì‹ ë¢°ë„: {results['confidence']:.3f}")
        
        if results['frames_with_faces'] > 0:
            fake_ratio = results['fake_frames'] / results['frames_with_faces'] * 100
            print(f"ğŸ“Š ë”¥í˜ì´í¬ ë¹„ìœ¨: {fake_ratio:.1f}%")
        
        # ê²°ê³¼ ì €ì¥
        if save_result:
            video_name = Path(video_path).stem
            json_path = f"video_result_{video_name}.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {json_path}")
        
        return results
    
    def run_webcam_demo(self, show_fps=True):
        """ì‹¤ì‹œê°„ ì›¹ìº  ë°ëª¨"""
        print("\nğŸ“¹ ì‹¤ì‹œê°„ ì›¹ìº  ë”¥í˜ì´í¬ íƒì§€ ì‹œì‘!")
        print("  - ì¢…ë£Œ: 'q' í‚¤")
        print("  - ìŠ¤í¬ë¦°ìƒ·: 's' í‚¤")
        print("  - í†µê³„ ì´ˆê¸°í™”: 'r' í‚¤")
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì„±ëŠ¥ ì¸¡ì • ë³€ìˆ˜
        frame_count = 0
        fps_start_time = time.time()
        fake_count = 0
        real_count = 0
        screenshot_count = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ë”¥í˜ì´í¬ íƒì§€
                start_time = time.time()
                results = self.detector.detect_deepfake_from_array(frame)
                process_time = time.time() - start_time
                
                # ê²°ê³¼ ì‹œê°í™”
                vis_frame = self.detector.visualize_results(frame, results)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                if results['overall_result'] == 'fake':
                    fake_count += 1
                elif results['overall_result'] == 'real':
                    real_count += 1
                
                # FPS ê³„ì‚°
                frame_count += 1
                if show_fps and frame_count % 30 == 0:
                    fps_time = time.time() - fps_start_time
                    fps = 30 / fps_time if fps_time > 0 else 0
                    fps_start_time = time.time()
                
                # ì •ë³´ ì˜¤ë²„ë ˆì´
                info_text = f"Result: {results['overall_result'].upper()}"
                confidence_text = f"Confidence: {results['confidence']:.3f}"
                stats_text = f"Fake: {fake_count} | Real: {real_count}"
                process_text = f"Process: {process_time*1000:.1f}ms"
                
                if show_fps and 'fps' in locals():
                    fps_text = f"FPS: {fps:.1f}"
                    cv2.putText(vis_frame, fps_text, (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                cv2.putText(vis_frame, info_text, (10, 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0) if results['overall_result'] == 'real' else (0, 0, 255), 2)
                cv2.putText(vis_frame, confidence_text, (10, 90), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(vis_frame, stats_text, (10, 120), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(vis_frame, process_text, (10, 150), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                # í™”ë©´ í‘œì‹œ
                cv2.imshow('Deepfake Detection Demo', vis_frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    screenshot_count += 1
                    screenshot_path = f"webcam_screenshot_{screenshot_count}.jpg"
                    cv2.imwrite(screenshot_path, vis_frame)
                    print(f"ğŸ“· ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")
                elif key == ord('r'):
                    fake_count = 0
                    real_count = 0
                    frame_count = 0
                    fps_start_time = time.time()
                    print("ğŸ“Š í†µê³„ ì´ˆê¸°í™”ë¨")
        
        except KeyboardInterrupt:
            print("\nâš ï¸  ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        
        finally:
            cap.release()
            cv2.destroyAllWindows()
            print(f"\nğŸ“ˆ ì›¹ìº  ë°ëª¨ ì¢…ë£Œ")
            print(f"  ğŸš¨ ë”¥í˜ì´í¬: {fake_count}íšŒ")
            print(f"  âœ… ì§„ì§œ: {real_count}íšŒ")
            print(f"  ğŸ“· ìŠ¤í¬ë¦°ìƒ·: {screenshot_count}ê°œ")

def main():
    parser = argparse.ArgumentParser(description='ë”¥í˜ì´í¬ íƒì§€ ì‹œìŠ¤í…œ ë°ëª¨')
    parser.add_argument('mode', choices=['image', 'batch', 'video', 'webcam'],
                       help='ë°ëª¨ ëª¨ë“œ')
    parser.add_argument('--input', type=str,
                       help='ì…ë ¥ íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--output', type=str, default='demo_results',
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--yolo_model', type=str,
                       help='ì»¤ìŠ¤í…€ YOLO ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--classifier_model', type=str,
                       help='í›ˆë ¨ëœ ë¶„ë¥˜ê¸° ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--confidence', type=float, default=0.5,
                       help='íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’')
    parser.add_argument('--frame_interval', type=int, default=30,
                       help='ë¹„ë””ì˜¤ í”„ë ˆì„ ìƒ˜í”Œë§ ê°„ê²©')
    parser.add_argument('--max_frames', type=int, default=100,
                       help='ë¹„ë””ì˜¤ ìµœëŒ€ ì²˜ë¦¬ í”„ë ˆì„ ìˆ˜')

    args = parser.parse_args()

    # ë°ëª¨ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    try:
        demo = DeepfakeDemo(
            yolo_model_path=args.yolo_model,
            classifier_weights_path=args.classifier_model,
            confidence_threshold=args.confidence
        )
    except Exception as e:
        print(f"\nâŒ ë°ëª¨ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("  1. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”: python prepare_data.py --image_dir input/images --label_dir input/labels")
        print("  2. í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”:")
        print("     --yolo_model runs/face_detection/face_detector/weights/best.pt")
        print("     --classifier_model runs/deepfake_classifier/best_model.pth")
        return 1

    # ëª¨ë“œë³„ ì‹¤í–‰
    try:
        if args.mode == 'image':
            if not args.input:
                print("âŒ ì´ë¯¸ì§€ ëª¨ë“œì—ëŠ” --input ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return 1
            demo.analyze_single_image(args.input)

        elif args.mode == 'batch':
            if not args.input:
                print("âŒ ë°°ì¹˜ ëª¨ë“œì—ëŠ” --input ë””ë ‰í† ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return 1
            demo.analyze_batch_images(args.input, args.output)

        elif args.mode == 'video':
            if not args.input:
                print("âŒ ë¹„ë””ì˜¤ ëª¨ë“œì—ëŠ” --input íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return 1
            demo.analyze_video(args.input, args.frame_interval, args.max_frames)

        elif args.mode == 'webcam':
            demo.run_webcam_demo()

        return 0
    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1

if __name__ == "__main__":
    main()

"""
ì‚¬ìš© ì˜ˆì œ:

1. ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„:
python demo.py image --input test_image.jpg

2. ë°°ì¹˜ ì´ë¯¸ì§€ ì²˜ë¦¬:
python demo.py batch --input test_images/ --output results/

3. ë¹„ë””ì˜¤ ë¶„ì„:
python demo.py video --input test_video.mp4 --frame_interval 15

4. ì‹¤ì‹œê°„ ì›¹ìº :
python demo.py webcam

5. ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš©:
python demo.py image --input test.jpg \
    --yolo_model runs/face_detection/best.pt \
    --classifier_model runs/classifier/best_model.pth \
    --confidence 0.7
"""