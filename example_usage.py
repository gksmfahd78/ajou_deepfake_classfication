import cv2
import os
from deepfake_detector import DeepfakeDetectionPipeline

def main():
    """ë”¥í˜ì´í¬ íƒì§€ íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì˜ˆì œ"""

    print("âš ï¸  ì¤‘ìš”: ì´ ì˜ˆì œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•´ì•¼ í•©ë‹ˆë‹¤!")
    print("í•™ìŠµ ë°©ë²•: python prepare_data.py --image_dir input/images --label_dir input/labels")
    print("ê·¸ í›„: python resume_training.py config\n")

    # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    yolo_model_path = "runs/face_detection/face_detector/weights/best.pt"
    classifier_weights_path = "runs/deepfake_classifier/best_model.pth"

    # í•™ìŠµëœ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
    models_exist = os.path.exists(yolo_model_path) and os.path.exists(classifier_weights_path)

    if not models_exist:
        print("âŒ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   YOLO ëª¨ë¸: {yolo_model_path} {'âœ“' if os.path.exists(yolo_model_path) else 'âœ—'}")
        print(f"   ë¶„ë¥˜ê¸° ëª¨ë¸: {classifier_weights_path} {'âœ“' if os.path.exists(classifier_weights_path) else 'âœ—'}")
        print("\nğŸ’¡ ê¸°ë³¸ ëª¨ë¸ë¡œ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ì •í™•ë„ê°€ ë§¤ìš° ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        response = input("ê³„ì†í•˜ë ¤ë©´ 'y'ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
        if response.lower() != 'y':
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        yolo_model_path = None
        classifier_weights_path = None

    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    try:
        print("\në”¥í˜ì´í¬ íƒì§€ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
        detector = DeepfakeDetectionPipeline(
            yolo_model_path=yolo_model_path,
            efficientnet_model='efficientnet-b0',
            classifier_weights_path=classifier_weights_path,
            confidence_threshold=0.5
        )
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ!\n")
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # ì´ë¯¸ì§€ ë¶„ì„ ì˜ˆì œ
    print("=== ì´ë¯¸ì§€ ë¶„ì„ ì˜ˆì œ ===")
    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ ì‹œë„
    possible_image_paths = ["sample_image.jpg", "test_image.jpg", "input/images/*.jpg"]
    image_path = None

    for path_pattern in possible_image_paths:
        if '*' in path_pattern:
            import glob
            matches = glob.glob(path_pattern)
            if matches:
                image_path = matches[0]
                break
        elif os.path.exists(path_pattern):
            image_path = path_pattern
            break

    if image_path and os.path.exists(image_path):
        # ì´ë¯¸ì§€ì—ì„œ ë”¥í˜ì´í¬ íƒì§€
        results = detector.detect_deepfake_from_image(image_path)

        print(f"íƒì§€ëœ ì–¼êµ´ ìˆ˜: {results['faces_detected']}")
        print(f"ì „ì²´ ê²°ê³¼: {results['overall_result']}")
        print(f"í‰ê·  ì‹ ë¢°ë„: {results['confidence']:.3f}")

        # ê° ì–¼êµ´ë³„ ê²°ê³¼
        for face in results.get('faces', []):
            print(f"ì–¼êµ´ {face['face_id']}: {face['prediction']} (ì‹ ë¢°ë„: {face['confidence']:.3f})")

        # ê²°ê³¼ ì‹œê°í™”
        image = cv2.imread(image_path)
        vis_image = detector.visualize_results(image, results)

        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        cv2.imwrite("result_image.jpg", vis_image)
        print("ê²°ê³¼ ì´ë¯¸ì§€ê°€ 'result_image.jpg'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    else:
        print(f"âš ï¸  í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ë‹¤ìŒ ìœ„ì¹˜ì— 'sample_image.jpg' íŒŒì¼ì„ ë°°ì¹˜í•˜ì„¸ìš”: {os.getcwd()}")

    # ë¹„ë””ì˜¤ ë¶„ì„ ì˜ˆì œ
    print("\n=== ë¹„ë””ì˜¤ ë¶„ì„ ì˜ˆì œ ===")
    video_path = "sample_video.mp4"  # í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ ê²½ë¡œ

    if os.path.exists(video_path):
        # ë¹„ë””ì˜¤ì—ì„œ ë”¥í˜ì´í¬ íƒì§€
        results = detector.detect_deepfake_from_video(
            video_path,
            frame_interval=30,  # 30í”„ë ˆì„ë§ˆë‹¤ ë¶„ì„
            max_frames=50      # ìµœëŒ€ 50í”„ë ˆì„ ë¶„ì„
        )

        print(f"ë¶„ì„ëœ í”„ë ˆì„ ìˆ˜: {results['total_frames_analyzed']}")
        print(f"ì–¼êµ´ì´ íƒì§€ëœ í”„ë ˆì„ ìˆ˜: {results['frames_with_faces']}")
        print(f"ê°€ì§œë¡œ íŒë‹¨ëœ í”„ë ˆì„ ìˆ˜: {results['fake_frames']}")
        print(f"ì§„ì§œë¡œ íŒë‹¨ëœ í”„ë ˆì„ ìˆ˜: {results['real_frames']}")
        print(f"ì „ì²´ ê²°ê³¼: {results['overall_result']}")
        print(f"í‰ê·  ì‹ ë¢°ë„: {results['confidence']:.3f}")

    else:
        print(f"âš ï¸  í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
    
    # ì›¹ìº  ì‹¤ì‹œê°„ ë¶„ì„ ì˜ˆì œ
    print("\n=== ì›¹ìº  ì‹¤ì‹œê°„ ë¶„ì„ ì˜ˆì œ ===")
    print("ì›¹ìº ì„ ì‹œì‘í•˜ë ¤ë©´ 'y'ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: 'q'í‚¤):")
    
    if input().lower() == 'y':
        cap = cv2.VideoCapture(0)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # í”„ë ˆì„ ë¶„ì„
            results = detector.detect_deepfake_from_array(frame)
            
            # ê²°ê³¼ ì‹œê°í™”
            vis_frame = detector.visualize_results(frame, results)
            
            # ì „ì²´ ê²°ê³¼ í‘œì‹œ
            overall_text = f"Overall: {results['overall_result']}"
            cv2.putText(vis_frame, overall_text, (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            cv2.imshow('Deepfake Detection', vis_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()