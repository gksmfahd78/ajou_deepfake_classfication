"""
ëª¨ë¸ì„ ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìœ í‹¸ë¦¬í‹°
"""

import os
import torch
import onnx
import onnxruntime as ort
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import argparse
from typing import Tuple, Optional
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from models.deepfake_classifier import DeepfakeClassifier


class ModelConverter:
    """ëª¨ë¸ ONNX ë³€í™˜ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    def convert_yolo_to_onnx(
        self,
        model_path: str,
        output_path: str,
        img_size: Tuple[int, int] = (640, 640),
        batch_size: int = 1,
        dynamic_batch: bool = False,
        half_precision: bool = False
    ) -> bool:
        """
        YOLO ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜
        
        Args:
            model_path: YOLO ëª¨ë¸ ê²½ë¡œ (.pt)
            output_path: ì¶œë ¥ ONNX íŒŒì¼ ê²½ë¡œ
            img_size: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
            batch_size: ë°°ì¹˜ í¬ê¸°
            dynamic_batch: ë™ì  ë°°ì¹˜ í¬ê¸° ì§€ì›
            half_precision: FP16 ì •ë°€ë„ ì‚¬ìš©
            
        Returns:
            ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"ğŸ”„ YOLO ëª¨ë¸ ONNX ë³€í™˜ ì‹œì‘: {model_path}")
            
            # YOLO ëª¨ë¸ ë¡œë“œ
            model = YOLO(model_path)
            
            # Ultralytics YOLOëŠ” ìì²´ export ë©”ì„œë“œ ì œê³µ
            success = model.export(
                format='onnx',
                imgsz=img_size,
                batch=batch_size,
                dynamic=dynamic_batch,
                half=half_precision,
                simplify=True,
                opset=11
            )
            
            if success:
                # ìƒì„±ëœ ONNX íŒŒì¼ì„ ì§€ì •ëœ ê²½ë¡œë¡œ ì´ë™
                generated_onnx = str(Path(model_path).with_suffix('.onnx'))
                if os.path.exists(generated_onnx):
                    os.makedirs(os.path.dirname(output_path), exist_ok=True)
                    if generated_onnx != output_path:
                        os.rename(generated_onnx, output_path)
                    
                    print(f"âœ… YOLO ONNX ë³€í™˜ ì™„ë£Œ: {output_path}")
                    
                    # ëª¨ë¸ ê²€ì¦
                    self._validate_onnx_model(output_path, img_size, batch_size)
                    return True
            
            return False
            
        except Exception as e:
            print(f"âŒ YOLO ONNX ë³€í™˜ ì‹¤íŒ¨: {e}")
            return False
    
    def convert_classifier_to_onnx(
        self,
        model_path: str,
        output_path: str,
        model_name: str = 'efficientnet-b0',
        img_size: Tuple[int, int] = (224, 224),
        batch_size: int = 1,
        dynamic_batch: bool = False,
        half_precision: bool = False
    ) -> bool:
        """
        EfficientNet ë¶„ë¥˜ê¸°ë¥¼ ONNXë¡œ ë³€í™˜
        
        Args:
            model_path: PyTorch ëª¨ë¸ ê²½ë¡œ (.pth)
            output_path: ì¶œë ¥ ONNX íŒŒì¼ ê²½ë¡œ
            model_name: EfficientNet ëª¨ë¸ ì´ë¦„
            img_size: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
            batch_size: ë°°ì¹˜ í¬ê¸°
            dynamic_batch: ë™ì  ë°°ì¹˜ í¬ê¸° ì§€ì›
            half_precision: FP16 ì •ë°€ë„ ì‚¬ìš©
            
        Returns:
            ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"ğŸ”„ ë¶„ë¥˜ê¸° ëª¨ë¸ ONNX ë³€í™˜ ì‹œì‘: {model_path}")
            
            # ëª¨ë¸ ì´ˆê¸°í™” ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
            model = DeepfakeClassifier(
                model_name=model_name,
                num_classes=2,
                pretrained=False
            )
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location=self.device)
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
            
            model.eval()
            model.to(self.device)
            
            # ë”ë¯¸ ì…ë ¥ ìƒì„±
            if dynamic_batch:
                dummy_input = torch.randn(1, 3, *img_size, device=self.device)
                dynamic_axes = {
                    'input': {0: 'batch_size'},
                    'output': {0: 'batch_size'}
                }
            else:
                dummy_input = torch.randn(batch_size, 3, *img_size, device=self.device)
                dynamic_axes = None
            
            # FP16 ë³€í™˜
            if half_precision and self.device.type == 'cuda':
                model.half()
                dummy_input = dummy_input.half()
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # ONNX ë³€í™˜
            torch.onnx.export(
                model,
                dummy_input,
                output_path,
                export_params=True,
                opset_version=11,
                do_constant_folding=True,
                input_names=['input'],
                output_names=['output'],
                dynamic_axes=dynamic_axes
            )
            
            print(f"âœ… ë¶„ë¥˜ê¸° ONNX ë³€í™˜ ì™„ë£Œ: {output_path}")
            
            # ëª¨ë¸ ê²€ì¦
            self._validate_onnx_model(output_path, img_size, batch_size)
            return True
            
        except Exception as e:
            print(f"âŒ ë¶„ë¥˜ê¸° ONNX ë³€í™˜ ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_onnx_model(
        self,
        onnx_path: str,
        img_size: Tuple[int, int],
        batch_size: int
    ):
        """ONNX ëª¨ë¸ ìœ íš¨ì„± ê²€ì¦"""
        try:
            # ONNX ëª¨ë¸ ë¡œë“œ ë° ê²€ì¦
            onnx_model = onnx.load(onnx_path)
            onnx.checker.check_model(onnx_model)
            
            # ONNX Runtimeìœ¼ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
            ort_session = ort.InferenceSession(onnx_path)
            
            # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
            if 'yolo' in onnx_path.lower() or 'face' in onnx_path.lower():
                # YOLO ëª¨ë¸ (640x640)
                dummy_input = np.random.randn(batch_size, 3, 640, 640).astype(np.float32)
            else:
                # ë¶„ë¥˜ê¸° ëª¨ë¸ (224x224)
                dummy_input = np.random.randn(batch_size, 3, *img_size).astype(np.float32)
            
            inputs = {ort_session.get_inputs()[0].name: dummy_input}
            outputs = ort_session.run(None, inputs)
            
            print(f"ğŸ” ONNX ëª¨ë¸ ê²€ì¦ ì™„ë£Œ:")
            print(f"  - ì…ë ¥ í˜•íƒœ: {dummy_input.shape}")
            print(f"  - ì¶œë ¥ í˜•íƒœ: {[out.shape for out in outputs]}")
            print(f"  - ëª¨ë¸ í¬ê¸°: {os.path.getsize(onnx_path) / (1024*1024):.2f} MB")
            
        except Exception as e:
            print(f"âš ï¸  ONNX ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    def convert_best_models(
        self,
        runs_dir: str = 'runs',
        output_dir: str = 'onnx_models',
        dynamic_batch: bool = True,
        half_precision: bool = False
    ):
        """
        ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ì„ ìë™ìœ¼ë¡œ ONNXë¡œ ë³€í™˜
        
        Args:
            runs_dir: í•™ìŠµ ê²°ê³¼ ë””ë ‰í† ë¦¬
            output_dir: ONNX ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
            dynamic_batch: ë™ì  ë°°ì¹˜ í¬ê¸° ì§€ì›
            half_precision: FP16 ì •ë°€ë„ ì‚¬ìš©
        """
        print("ğŸ¯ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ ìë™ ONNX ë³€í™˜ ì‹œì‘...")
        
        from utils.checkpoint_manager import CheckpointManager
        
        # ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        manager = CheckpointManager(runs_dir)
        
        # YOLO ëª¨ë¸ ë³€í™˜
        print("\nğŸ“Š YOLO ëª¨ë¸ ë³€í™˜ ì¤‘...")
        yolo_checkpoint = manager.find_best_checkpoint('yolo')
        if yolo_checkpoint:
            yolo_output = os.path.join(output_dir, 'yolo_face_detector.onnx')
            success = self.convert_yolo_to_onnx(
                yolo_checkpoint,
                yolo_output,
                dynamic_batch=dynamic_batch,
                half_precision=half_precision
            )
            if success:
                print(f"âœ… YOLO ëª¨ë¸ ë³€í™˜ ì™„ë£Œ: {yolo_output}")
        else:
            print("âŒ YOLO ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë¶„ë¥˜ê¸° ëª¨ë¸ ë³€í™˜
        print("\nğŸ§  ë¶„ë¥˜ê¸° ëª¨ë¸ ë³€í™˜ ì¤‘...")
        classifier_checkpoint = manager.find_best_checkpoint('classifier')
        if classifier_checkpoint:
            classifier_output = os.path.join(output_dir, 'deepfake_classifier.onnx')
            success = self.convert_classifier_to_onnx(
                classifier_checkpoint,
                classifier_output,
                dynamic_batch=dynamic_batch,
                half_precision=half_precision
            )
            if success:
                print(f"âœ… ë¶„ë¥˜ê¸° ëª¨ë¸ ë³€í™˜ ì™„ë£Œ: {classifier_output}")
        else:
            print("âŒ ë¶„ë¥˜ê¸° ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"\nğŸ‰ ONNX ë³€í™˜ ì™„ë£Œ! ëª¨ë¸ë“¤ì´ '{output_dir}' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def benchmark_models(
        self,
        pytorch_model_path: str,
        onnx_model_path: str,
        num_runs: int = 100,
        batch_size: int = 1
    ):
        """PyTorch vs ONNX ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
        print(f"âš¡ ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ë°°ì¹˜í¬ê¸°: {batch_size}, ë°˜ë³µ: {num_runs}íšŒ)")
        
        try:
            import time
            
            # ONNX ëª¨ë¸ í…ŒìŠ¤íŠ¸
            ort_session = ort.InferenceSession(onnx_model_path)
            input_name = ort_session.get_inputs()[0].name
            input_shape = ort_session.get_inputs()[0].shape
            
            # ì…ë ¥ í˜•íƒœ ê²°ì •
            if len(input_shape) == 4:
                if input_shape[2] == 640:  # YOLO
                    dummy_input = np.random.randn(batch_size, 3, 640, 640).astype(np.float32)
                else:  # Classifier
                    dummy_input = np.random.randn(batch_size, 3, 224, 224).astype(np.float32)
            
            # ONNX ì„±ëŠ¥ ì¸¡ì •
            start_time = time.time()
            for _ in range(num_runs):
                _ = ort_session.run(None, {input_name: dummy_input})
            onnx_time = (time.time() - start_time) / num_runs
            
            print(f"ğŸ”¥ ONNX í‰ê·  ì¶”ë¡  ì‹œê°„: {onnx_time*1000:.2f}ms")
            print(f"ğŸ“Š ONNX FPS: {1/onnx_time:.1f}")
            
        except Exception as e:
            print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")


def main():
    parser = argparse.ArgumentParser(description='ëª¨ë¸ ONNX ë³€í™˜ ë„êµ¬')
    parser.add_argument('command', choices=['yolo', 'classifier', 'best', 'benchmark'],
                       help='ë³€í™˜í•  ëª¨ë¸ íƒ€ì…')
    
    # ê³µí†µ ì¸ìˆ˜
    parser.add_argument('--input', type=str, help='ì…ë ¥ ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--output', type=str, help='ì¶œë ¥ ONNX íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--dynamic_batch', action='store_true',
                       help='ë™ì  ë°°ì¹˜ í¬ê¸° ì§€ì›')
    parser.add_argument('--half_precision', action='store_true',
                       help='FP16 ì •ë°€ë„ ì‚¬ìš©')
    parser.add_argument('--batch_size', type=int, default=1,
                       help='ë°°ì¹˜ í¬ê¸°')
    
    # ëª¨ë¸ë³„ ì¸ìˆ˜
    parser.add_argument('--model_name', type=str, default='efficientnet-b0',
                       help='EfficientNet ëª¨ë¸ ì´ë¦„')
    parser.add_argument('--img_size', type=int, nargs=2, default=[224, 224],
                       help='ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°')
    
    # ìë™ ë³€í™˜ ì¸ìˆ˜
    parser.add_argument('--runs_dir', type=str, default='runs',
                       help='í•™ìŠµ ê²°ê³¼ ë””ë ‰í† ë¦¬')
    parser.add_argument('--output_dir', type=str, default='onnx_models',
                       help='ONNX ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬')
    
    # ë²¤ì¹˜ë§ˆí¬ ì¸ìˆ˜
    parser.add_argument('--pytorch_model', type=str,
                       help='PyTorch ëª¨ë¸ ê²½ë¡œ (ë²¤ì¹˜ë§ˆí¬ìš©)')
    parser.add_argument('--onnx_model', type=str,
                       help='ONNX ëª¨ë¸ ê²½ë¡œ (ë²¤ì¹˜ë§ˆí¬ìš©)')
    parser.add_argument('--num_runs', type=int, default=100,
                       help='ë²¤ì¹˜ë§ˆí¬ ë°˜ë³µ íšŸìˆ˜')
    
    args = parser.parse_args()
    
    converter = ModelConverter()
    
    if args.command == 'yolo':
        if not args.input or not args.output:
            print("âŒ YOLO ë³€í™˜ì—ëŠ” --inputê³¼ --outputì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        success = converter.convert_yolo_to_onnx(
            args.input,
            args.output,
            img_size=(640, 640),
            batch_size=args.batch_size,
            dynamic_batch=args.dynamic_batch,
            half_precision=args.half_precision
        )
        
    elif args.command == 'classifier':
        if not args.input or not args.output:
            print("âŒ ë¶„ë¥˜ê¸° ë³€í™˜ì—ëŠ” --inputê³¼ --outputì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        success = converter.convert_classifier_to_onnx(
            args.input,
            args.output,
            model_name=args.model_name,
            img_size=tuple(args.img_size),
            batch_size=args.batch_size,
            dynamic_batch=args.dynamic_batch,
            half_precision=args.half_precision
        )
        
    elif args.command == 'best':
        converter.convert_best_models(
            runs_dir=args.runs_dir,
            output_dir=args.output_dir,
            dynamic_batch=args.dynamic_batch,
            half_precision=args.half_precision
        )
        
    elif args.command == 'benchmark':
        if not args.pytorch_model or not args.onnx_model:
            print("âŒ ë²¤ì¹˜ë§ˆí¬ì—ëŠ” --pytorch_modelê³¼ --onnx_modelì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        converter.benchmark_models(
            args.pytorch_model,
            args.onnx_model,
            num_runs=args.num_runs,
            batch_size=args.batch_size
        )


if __name__ == "__main__":
    main()

"""
ì‚¬ìš© ì˜ˆì œ:

1. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ ìë™ ë³€í™˜:
python model_converter.py best --output_dir onnx_models --dynamic_batch

2. íŠ¹ì • YOLO ëª¨ë¸ ë³€í™˜:
python model_converter.py yolo --input runs/face_detection/best.pt --output models/yolo_face.onnx

3. íŠ¹ì • ë¶„ë¥˜ê¸° ëª¨ë¸ ë³€í™˜:
python model_converter.py classifier --input runs/classifier/best_model.pth --output models/classifier.onnx

4. FP16 ì •ë°€ë„ë¡œ ë³€í™˜:
python model_converter.py best --half_precision --output_dir onnx_models_fp16

5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬:
python model_converter.py benchmark --pytorch_model runs/classifier/best_model.pth --onnx_model onnx_models/classifier.onnx

ë³€í™˜ëœ ONNX ëª¨ë¸ ì¥ì :
- ì¶”ë¡  ì†ë„ 2-5ë°° í–¥ìƒ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
- ë‹¤ì–‘í•œ í”Œë«í¼ ì§€ì› (CPU ìµœì í™”)
- ë°°í¬ í™˜ê²½ì—ì„œ ì•ˆì •ì„± í–¥ìƒ
"""